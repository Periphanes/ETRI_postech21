{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import torch\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import AutoTokenizer, ElectraForSequenceClassification, AdamW\n",
    "from tqdm.notebook import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GPU 사용\n",
    "device = torch.device(\"cuda\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NSMCDataset(Dataset):\n",
    "  \n",
    "  def __init__(self, csv_file):\n",
    "    # 일부 값중에 NaN이 있음...\n",
    "    self.dataset = pd.read_csv(csv_file, sep='\\t').dropna(axis=0) \n",
    "    # 중복제거\n",
    "    self.dataset.drop_duplicates(subset=['document'], inplace=True)\n",
    "    self.tokenizer = AutoTokenizer.from_pretrained(\"beomi/KcELECTRA-base\")\n",
    "\n",
    "    print(self.dataset.describe())\n",
    "  \n",
    "  def __len__(self):\n",
    "    return len(self.dataset)\n",
    "  \n",
    "  def __getitem__(self, idx):\n",
    "    row = self.dataset.iloc[idx, 1:3].values\n",
    "    text = row[0]\n",
    "    y = row[1]\n",
    "\n",
    "    inputs = self.tokenizer(\n",
    "        text, \n",
    "        return_tensors='pt',\n",
    "        truncation=True,\n",
    "        max_length=256,\n",
    "        pad_to_max_length=True,\n",
    "        add_special_tokens=True\n",
    "        )\n",
    "    \n",
    "    input_ids = inputs['input_ids'][0]\n",
    "    attention_mask = inputs['attention_mask'][0]\n",
    "\n",
    "    return input_ids, attention_mask, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                 id          label\n",
      "count  1.461820e+05  146182.000000\n",
      "mean   6.779186e+06       0.498283\n",
      "std    2.919223e+06       0.499999\n",
      "min    3.300000e+01       0.000000\n",
      "25%    4.814832e+06       0.000000\n",
      "50%    7.581160e+06       0.000000\n",
      "75%    9.274760e+06       1.000000\n",
      "max    1.027815e+07       1.000000\n",
      "                 id         label\n",
      "count  4.915700e+04  49157.000000\n",
      "mean   6.752945e+06      0.502695\n",
      "std    2.937158e+06      0.499998\n",
      "min    6.010000e+02      0.000000\n",
      "25%    4.777143e+06      0.000000\n",
      "50%    7.565415e+06      1.000000\n",
      "75%    9.260204e+06      1.000000\n",
      "max    1.027809e+07      1.000000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = NSMCDataset(\"ratings_train.txt\")\n",
    "test_dataset = NSMCDataset(\"ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at beomi/KcELECTRA-base were not used when initializing ElectraForSequenceClassification: ['discriminator_predictions.dense_prediction.weight', 'discriminator_predictions.dense_prediction.bias', 'discriminator_predictions.dense.bias', 'discriminator_predictions.dense.weight']\n",
      "- This IS expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing ElectraForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of ElectraForSequenceClassification were not initialized from the model checkpoint at beomi/KcELECTRA-base and are newly initialized: ['classifier.dense.weight', 'classifier.dense.bias', 'classifier.out_proj.weight', 'classifier.out_proj.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "model = ElectraForSequenceClassification.from_pretrained(\"beomi/KcELECTRA-base\").to(device)\n",
    "\n",
    "# 한번 실행해보기\n",
    "# text, attention_mask, y = train_dataset[0]\n",
    "# model(text.unsqueeze(0).to(device), attention_mask=attention_mask.unsqueeze(0).to(device))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_state_dict(torch.load(\"model.pt\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ElectraForSequenceClassification(\n",
       "  (electra): ElectraModel(\n",
       "    (embeddings): ElectraEmbeddings(\n",
       "      (word_embeddings): Embedding(50135, 768, padding_idx=0)\n",
       "      (position_embeddings): Embedding(512, 768)\n",
       "      (token_type_embeddings): Embedding(2, 768)\n",
       "      (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "      (dropout): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (encoder): ElectraEncoder(\n",
       "      (layer): ModuleList(\n",
       "        (0-11): 12 x ElectraLayer(\n",
       "          (attention): ElectraAttention(\n",
       "            (self): ElectraSelfAttention(\n",
       "              (query): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (key): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (value): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "            (output): ElectraSelfOutput(\n",
       "              (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "            )\n",
       "          )\n",
       "          (intermediate): ElectraIntermediate(\n",
       "            (dense): Linear(in_features=768, out_features=3072, bias=True)\n",
       "            (intermediate_act_fn): GELUActivation()\n",
       "          )\n",
       "          (output): ElectraOutput(\n",
       "            (dense): Linear(in_features=3072, out_features=768, bias=True)\n",
       "            (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (dropout): Dropout(p=0.1, inplace=False)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classifier): ElectraClassificationHead(\n",
       "    (dense): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (dropout): Dropout(p=0.1, inplace=False)\n",
       "    (out_proj): Linear(in_features=768, out_features=2, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 모델 레이어 보기\n",
    "model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\anaconda3\\envs\\ETRI\\lib\\site-packages\\transformers\\optimization.py:391: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "optimizer = AdamW(model.parameters(), lr=5e-6)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=16, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aac1c8a0882c47f3955d258ef2f0716a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/9137 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\programs\\anaconda3\\envs\\ETRI\\lib\\site-packages\\transformers\\tokenization_utils_base.py:2346: FutureWarning: The `pad_to_max_length` argument is deprecated and will be removed in a future version, use `padding=True` or `padding='longest'` to pad to the longest sequence in the batch, or use `padding='max_length'` to pad to a max length. In this case, you can give a specific length with `max_length` (e.g. `max_length=45`) or leave max_length to None to pad to the maximal input size of the model (e.g. 512 for Bert).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1026, -0.0060],\n",
      "        [ 0.1221,  0.0106],\n",
      "        [ 0.0571,  0.0447],\n",
      "        [ 0.0880, -0.0558],\n",
      "        [ 0.0693,  0.0351],\n",
      "        [ 0.0472,  0.0213],\n",
      "        [ 0.1281,  0.0436],\n",
      "        [ 0.0575, -0.0287],\n",
      "        [ 0.1495,  0.0455],\n",
      "        [ 0.0456,  0.0379],\n",
      "        [ 0.0590,  0.0270],\n",
      "        [-0.0061, -0.0054],\n",
      "        [ 0.1141,  0.0691],\n",
      "        [ 0.0597, -0.0110],\n",
      "        [ 0.0943,  0.0655],\n",
      "        [ 0.0601, -0.0260]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1229,  0.0364],\n",
      "        [ 0.0070,  0.0815],\n",
      "        [ 0.1101,  0.0424],\n",
      "        [ 0.0207, -0.0050],\n",
      "        [ 0.0188, -0.0506],\n",
      "        [ 0.0689,  0.1082],\n",
      "        [ 0.0049,  0.0496],\n",
      "        [ 0.1163,  0.0123],\n",
      "        [ 0.0501, -0.0268],\n",
      "        [ 0.1068, -0.0113],\n",
      "        [ 0.1456, -0.0174],\n",
      "        [ 0.0106, -0.0507],\n",
      "        [ 0.1782,  0.0198],\n",
      "        [ 0.0841, -0.0312],\n",
      "        [ 0.0200,  0.1056],\n",
      "        [ 0.0331, -0.0106]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0387, -0.0103],\n",
      "        [ 0.0913,  0.0007],\n",
      "        [ 0.0894,  0.0758],\n",
      "        [ 0.0496, -0.0203],\n",
      "        [ 0.1017,  0.0184],\n",
      "        [ 0.1176,  0.0734],\n",
      "        [ 0.0873,  0.0072],\n",
      "        [ 0.0214, -0.0146],\n",
      "        [ 0.0639,  0.0006],\n",
      "        [ 0.0933,  0.0028],\n",
      "        [ 0.0424,  0.0279],\n",
      "        [ 0.0533, -0.0105],\n",
      "        [ 0.1396,  0.0448],\n",
      "        [ 0.0853,  0.0129],\n",
      "        [ 0.1351,  0.0340],\n",
      "        [-0.0281, -0.0153]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0896,  0.0383],\n",
      "        [-0.0052,  0.0329],\n",
      "        [ 0.0724,  0.0387],\n",
      "        [ 0.1119,  0.0701],\n",
      "        [ 0.0368, -0.0241],\n",
      "        [ 0.0324,  0.0110],\n",
      "        [ 0.1255,  0.0210],\n",
      "        [ 0.1027,  0.0562],\n",
      "        [ 0.1162,  0.0122],\n",
      "        [ 0.1675, -0.0343],\n",
      "        [ 0.0709, -0.0156],\n",
      "        [ 0.0476, -0.0319],\n",
      "        [ 0.1046,  0.0004],\n",
      "        [ 0.0399,  0.0087],\n",
      "        [ 0.0005,  0.0428],\n",
      "        [ 0.0985, -0.0052]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0698,  0.0677],\n",
      "        [ 0.0679, -0.0106],\n",
      "        [ 0.0800,  0.0702],\n",
      "        [ 0.0426,  0.0044],\n",
      "        [ 0.0373,  0.1765],\n",
      "        [ 0.1103, -0.0287],\n",
      "        [ 0.0429, -0.0632],\n",
      "        [ 0.0711,  0.0814],\n",
      "        [ 0.1215, -0.0791],\n",
      "        [ 0.0259, -0.0030],\n",
      "        [ 0.0545,  0.0529],\n",
      "        [ 0.0918, -0.0952],\n",
      "        [ 0.0612,  0.0488],\n",
      "        [ 0.0701,  0.0161],\n",
      "        [ 0.0377, -0.0408],\n",
      "        [ 0.1102,  0.0198]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0646,  0.0300],\n",
      "        [ 0.0426,  0.0426],\n",
      "        [-0.0115,  0.0928],\n",
      "        [ 0.1331,  0.0052],\n",
      "        [ 0.0501,  0.0507],\n",
      "        [ 0.0379,  0.1140],\n",
      "        [ 0.0117,  0.0569],\n",
      "        [ 0.0451, -0.0165],\n",
      "        [ 0.0490, -0.0120],\n",
      "        [ 0.0229,  0.0418],\n",
      "        [ 0.1146, -0.0145],\n",
      "        [ 0.0489,  0.0471],\n",
      "        [ 0.1074, -0.0779],\n",
      "        [ 0.0060,  0.0007],\n",
      "        [ 0.0910,  0.0483],\n",
      "        [ 0.1066,  0.0739]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0821,  0.0042],\n",
      "        [ 0.1143,  0.0523],\n",
      "        [ 0.0031,  0.0794],\n",
      "        [ 0.0505,  0.0168],\n",
      "        [ 0.0402,  0.0513],\n",
      "        [ 0.0646,  0.0400],\n",
      "        [ 0.1610, -0.0144],\n",
      "        [ 0.0630,  0.0366],\n",
      "        [ 0.1645, -0.0256],\n",
      "        [ 0.0340,  0.0077],\n",
      "        [ 0.0482,  0.0349],\n",
      "        [ 0.1247, -0.0097],\n",
      "        [ 0.0507,  0.0451],\n",
      "        [ 0.0542,  0.1030],\n",
      "        [-0.0004, -0.0217],\n",
      "        [ 0.0252, -0.0164]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0308,  0.0553],\n",
      "        [ 0.1699, -0.0023],\n",
      "        [ 0.1221,  0.0385],\n",
      "        [ 0.0685,  0.0173],\n",
      "        [ 0.0594, -0.0784],\n",
      "        [ 0.0901, -0.0289],\n",
      "        [ 0.0374,  0.0096],\n",
      "        [ 0.0454,  0.0460],\n",
      "        [ 0.0812,  0.0189],\n",
      "        [ 0.0589,  0.0773],\n",
      "        [ 0.0957,  0.0429],\n",
      "        [ 0.0407,  0.0614],\n",
      "        [ 0.0368,  0.1122],\n",
      "        [-0.0095, -0.0759],\n",
      "        [ 0.0457,  0.0060],\n",
      "        [ 0.0864,  0.1069]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0266,  0.0128],\n",
      "        [ 0.0590,  0.0668],\n",
      "        [ 0.1564,  0.0006],\n",
      "        [ 0.0285, -0.0185],\n",
      "        [ 0.1273, -0.0262],\n",
      "        [ 0.1352,  0.0626],\n",
      "        [ 0.1197, -0.0554],\n",
      "        [ 0.1016,  0.0145],\n",
      "        [ 0.0689,  0.0384],\n",
      "        [ 0.1341,  0.0361],\n",
      "        [-0.0645,  0.0449],\n",
      "        [ 0.0070,  0.0508],\n",
      "        [-0.0161,  0.0640],\n",
      "        [ 0.0563, -0.0680],\n",
      "        [ 0.0703,  0.0902],\n",
      "        [ 0.0548, -0.0549]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0386,  0.0551],\n",
      "        [ 0.0342,  0.1031],\n",
      "        [ 0.0489,  0.0974],\n",
      "        [ 0.0946,  0.0296],\n",
      "        [-0.0453,  0.0378],\n",
      "        [ 0.0933, -0.0064],\n",
      "        [ 0.0394,  0.0268],\n",
      "        [ 0.0528, -0.0562],\n",
      "        [ 0.1134,  0.1290],\n",
      "        [ 0.0686,  0.0266],\n",
      "        [ 0.0622,  0.0004],\n",
      "        [-0.0118, -0.0003],\n",
      "        [ 0.0833,  0.0921],\n",
      "        [ 0.0060, -0.0260],\n",
      "        [ 0.0744,  0.0932],\n",
      "        [ 0.1221,  0.0529]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1458,  0.0985],\n",
      "        [ 0.0917,  0.0232],\n",
      "        [ 0.0807,  0.0525],\n",
      "        [ 0.0484, -0.0062],\n",
      "        [ 0.1245,  0.0595],\n",
      "        [ 0.0885, -0.0236],\n",
      "        [ 0.0122,  0.0659],\n",
      "        [ 0.1807, -0.0695],\n",
      "        [ 0.1370, -0.0278],\n",
      "        [ 0.0841,  0.0477],\n",
      "        [ 0.0552,  0.0444],\n",
      "        [ 0.0494,  0.0144],\n",
      "        [ 0.0419,  0.1078],\n",
      "        [ 0.1081,  0.0254],\n",
      "        [ 0.0641,  0.0279],\n",
      "        [ 0.1452,  0.0517]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0619, -0.0483],\n",
      "        [ 0.0680, -0.0384],\n",
      "        [ 0.1135,  0.0237],\n",
      "        [ 0.1128,  0.0716],\n",
      "        [ 0.2004,  0.0205],\n",
      "        [ 0.1013, -0.0004],\n",
      "        [-0.0184,  0.0699],\n",
      "        [ 0.0365, -0.0118],\n",
      "        [-0.0355,  0.0356],\n",
      "        [ 0.0130,  0.0363],\n",
      "        [ 0.0602, -0.0428],\n",
      "        [ 0.0613,  0.0247],\n",
      "        [ 0.1279,  0.0582],\n",
      "        [ 0.0842,  0.0606],\n",
      "        [ 0.1006,  0.0604],\n",
      "        [ 0.0725,  0.0358]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0819, -0.0054],\n",
      "        [ 0.0409,  0.0455],\n",
      "        [ 0.0234,  0.0803],\n",
      "        [-0.0105,  0.0035],\n",
      "        [ 0.1476,  0.0234],\n",
      "        [ 0.1223,  0.0086],\n",
      "        [ 0.0536,  0.0176],\n",
      "        [ 0.0584,  0.0390],\n",
      "        [ 0.0779, -0.0082],\n",
      "        [ 0.0605,  0.0260],\n",
      "        [ 0.0090, -0.0237],\n",
      "        [ 0.0287, -0.0202],\n",
      "        [ 0.0601, -0.0712],\n",
      "        [ 0.0739, -0.0031],\n",
      "        [ 0.0470,  0.0735],\n",
      "        [ 0.0394,  0.0250]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 2.5909e-02,  2.5348e-02],\n",
      "        [ 5.6302e-02,  7.8368e-02],\n",
      "        [ 8.4402e-02,  6.2950e-02],\n",
      "        [-4.5824e-02,  6.5418e-02],\n",
      "        [ 5.7902e-02,  5.0247e-02],\n",
      "        [ 8.3201e-02,  4.3361e-05],\n",
      "        [ 9.3677e-02,  4.3896e-02],\n",
      "        [ 4.8418e-02, -1.0383e-02],\n",
      "        [ 7.1802e-04, -2.4093e-02],\n",
      "        [ 4.4602e-02,  3.4294e-02],\n",
      "        [-3.6663e-02, -6.7778e-02],\n",
      "        [ 6.6682e-02,  4.2284e-02],\n",
      "        [ 5.3519e-02,  2.8762e-02],\n",
      "        [ 8.6550e-02, -1.9480e-02],\n",
      "        [ 3.1353e-02,  8.8109e-02],\n",
      "        [ 9.7336e-02,  7.4735e-02]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.0317,  0.0477],\n",
      "        [ 0.1256,  0.0857],\n",
      "        [ 0.0813,  0.0509],\n",
      "        [ 0.0454,  0.0429],\n",
      "        [ 0.0700,  0.0600],\n",
      "        [ 0.0806,  0.0296],\n",
      "        [ 0.0265,  0.0757],\n",
      "        [ 0.0668, -0.0215],\n",
      "        [ 0.0824, -0.0289],\n",
      "        [ 0.1028,  0.0187],\n",
      "        [ 0.0724,  0.1296],\n",
      "        [ 0.0907,  0.0568],\n",
      "        [ 0.0753, -0.0340],\n",
      "        [ 0.0138, -0.0133],\n",
      "        [ 0.0213, -0.0148],\n",
      "        [ 0.0695, -0.0393]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[ 0.1545,  0.0677],\n",
      "        [ 0.1917,  0.0248],\n",
      "        [ 0.0370,  0.0666],\n",
      "        [ 0.0408,  0.0321],\n",
      "        [-0.0042, -0.0122],\n",
      "        [ 0.1259, -0.0037],\n",
      "        [ 0.0097, -0.0343],\n",
      "        [ 0.0724,  0.0043],\n",
      "        [ 0.0451,  0.0589],\n",
      "        [ 0.0589, -0.0131],\n",
      "        [ 0.1183,  0.0027],\n",
      "        [ 0.0765,  0.0827],\n",
      "        [ 0.0177,  0.0021],\n",
      "        [ 0.0175,  0.0392],\n",
      "        [ 0.1277,  0.0824],\n",
      "        [ 0.1253,  0.0674]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0328,  0.0279],\n",
      "        [ 0.0723,  0.0529],\n",
      "        [ 0.0093,  0.0230],\n",
      "        [ 0.0271,  0.0547],\n",
      "        [ 0.1420, -0.0605],\n",
      "        [ 0.0917,  0.0168],\n",
      "        [ 0.0388, -0.0137],\n",
      "        [ 0.0848,  0.0494],\n",
      "        [ 0.0724, -0.0598],\n",
      "        [ 0.0781, -0.0260],\n",
      "        [ 0.0790, -0.0468],\n",
      "        [-0.0335,  0.0223],\n",
      "        [ 0.0506,  0.0317],\n",
      "        [ 0.1120, -0.0351],\n",
      "        [ 0.1475, -0.0314],\n",
      "        [ 0.0335, -0.0245]], device='cuda:0', grad_fn=<AddmmBackward0>)\n",
      "tensor([[-0.0107, -0.0420],\n",
      "        [ 0.1015,  0.0203],\n",
      "        [ 0.0642, -0.0398],\n",
      "        [ 0.0383,  0.0564],\n",
      "        [ 0.1477,  0.0027],\n",
      "        [ 0.0932, -0.0464],\n",
      "        [ 0.0519,  0.0674],\n",
      "        [ 0.0685, -0.0027],\n",
      "        [ 0.0859, -0.0164],\n",
      "        [ 0.0354, -0.0114],\n",
      "        [ 0.1637,  0.0353],\n",
      "        [ 0.0433, -0.0051],\n",
      "        [ 0.1639,  0.0120],\n",
      "        [-0.0294, -0.1522],\n",
      "        [ 0.0308, -0.0392],\n",
      "        [ 0.1092,  0.0448]], device='cuda:0', grad_fn=<AddmmBackward0>)\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 16\u001b[0m\n\u001b[0;32m     14\u001b[0m y_batch \u001b[39m=\u001b[39m y_batch\u001b[39m.\u001b[39mto(device)\n\u001b[0;32m     15\u001b[0m y_pred \u001b[39m=\u001b[39m model(input_ids_batch\u001b[39m.\u001b[39mto(device), attention_mask\u001b[39m=\u001b[39mattention_masks_batch\u001b[39m.\u001b[39mto(device))[\u001b[39m0\u001b[39m]\n\u001b[1;32m---> 16\u001b[0m \u001b[39mprint\u001b[39;49m(y_pred)\n\u001b[0;32m     17\u001b[0m loss \u001b[39m=\u001b[39m F\u001b[39m.\u001b[39mcross_entropy(y_pred, y_batch)\n\u001b[0;32m     18\u001b[0m loss\u001b[39m.\u001b[39mbackward()\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ETRI\\lib\\site-packages\\torch\\_tensor.py:426\u001b[0m, in \u001b[0;36mTensor.__repr__\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    422\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[0;32m    423\u001b[0m         Tensor\u001b[39m.\u001b[39m\u001b[39m__repr__\u001b[39m, (\u001b[39mself\u001b[39m,), \u001b[39mself\u001b[39m, tensor_contents\u001b[39m=\u001b[39mtensor_contents\n\u001b[0;32m    424\u001b[0m     )\n\u001b[0;32m    425\u001b[0m \u001b[39m# All strings are unicode in Python 3.\u001b[39;00m\n\u001b[1;32m--> 426\u001b[0m \u001b[39mreturn\u001b[39;00m torch\u001b[39m.\u001b[39;49m_tensor_str\u001b[39m.\u001b[39;49m_str(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ETRI\\lib\\site-packages\\torch\\_tensor_str.py:636\u001b[0m, in \u001b[0;36m_str\u001b[1;34m(self, tensor_contents)\u001b[0m\n\u001b[0;32m    634\u001b[0m \u001b[39mwith\u001b[39;00m torch\u001b[39m.\u001b[39mno_grad(), torch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39m_python_dispatch\u001b[39m.\u001b[39m_disable_current_modes():\n\u001b[0;32m    635\u001b[0m     guard \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_DisableFuncTorch()\n\u001b[1;32m--> 636\u001b[0m     \u001b[39mreturn\u001b[39;00m _str_intern(\u001b[39mself\u001b[39;49m, tensor_contents\u001b[39m=\u001b[39;49mtensor_contents)\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ETRI\\lib\\site-packages\\torch\\_tensor_str.py:567\u001b[0m, in \u001b[0;36m_str_intern\u001b[1;34m(inp, tensor_contents)\u001b[0m\n\u001b[0;32m    565\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mto_dense(), indent)\n\u001b[0;32m    566\u001b[0m                 \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 567\u001b[0m                     tensor_str \u001b[39m=\u001b[39m _tensor_str(\u001b[39mself\u001b[39;49m, indent)\n\u001b[0;32m    569\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout \u001b[39m!=\u001b[39m torch\u001b[39m.\u001b[39mstrided:\n\u001b[0;32m    570\u001b[0m     suffixes\u001b[39m.\u001b[39mappend(\u001b[39m\"\u001b[39m\u001b[39mlayout=\u001b[39m\u001b[39m\"\u001b[39m \u001b[39m+\u001b[39m \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlayout))\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ETRI\\lib\\site-packages\\torch\\_tensor_str.py:327\u001b[0m, in \u001b[0;36m_tensor_str\u001b[1;34m(self, indent)\u001b[0m\n\u001b[0;32m    323\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\n\u001b[0;32m    324\u001b[0m         \u001b[39mself\u001b[39m, indent, summarize, real_formatter, imag_formatter\n\u001b[0;32m    325\u001b[0m     )\n\u001b[0;32m    326\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 327\u001b[0m     formatter \u001b[39m=\u001b[39m _Formatter(get_summarized_data(\u001b[39mself\u001b[39;49m) \u001b[39mif\u001b[39;49;00m summarize \u001b[39melse\u001b[39;49;00m \u001b[39mself\u001b[39;49m)\n\u001b[0;32m    328\u001b[0m     \u001b[39mreturn\u001b[39;00m _tensor_str_with_formatter(\u001b[39mself\u001b[39m, indent, summarize, formatter)\n",
      "File \u001b[1;32md:\\programs\\anaconda3\\envs\\ETRI\\lib\\site-packages\\torch\\_tensor_str.py:115\u001b[0m, in \u001b[0;36m_Formatter.__init__\u001b[1;34m(self, tensor)\u001b[0m\n\u001b[0;32m    112\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width \u001b[39m=\u001b[39m \u001b[39mmax\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mmax_width, \u001b[39mlen\u001b[39m(value_str))\n\u001b[0;32m    114\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m     nonzero_finite_vals \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mmasked_select(\n\u001b[0;32m    116\u001b[0m         tensor_view, torch\u001b[39m.\u001b[39;49misfinite(tensor_view) \u001b[39m&\u001b[39;49m tensor_view\u001b[39m.\u001b[39;49mne(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m    117\u001b[0m     )\n\u001b[0;32m    119\u001b[0m     \u001b[39mif\u001b[39;00m nonzero_finite_vals\u001b[39m.\u001b[39mnumel() \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    120\u001b[0m         \u001b[39m# no valid number, do nothing\u001b[39;00m\n\u001b[0;32m    121\u001b[0m         \u001b[39mreturn\u001b[39;00m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "losses = []\n",
    "accuracies = []\n",
    "\n",
    "for i in range(epochs):\n",
    "  total_loss = 0.0\n",
    "  correct = 0\n",
    "  total = 0\n",
    "  batches = 0\n",
    "\n",
    "  model.train()\n",
    "\n",
    "  for input_ids_batch, attention_masks_batch, y_batch in tqdm(train_loader):\n",
    "    optimizer.zero_grad()\n",
    "    y_batch = y_batch.to(device)\n",
    "    y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
    "    loss = F.cross_entropy(y_pred, y_batch)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    total_loss += loss.item()\n",
    "\n",
    "    _, predicted = torch.max(y_pred, 1)\n",
    "    correct += (predicted == y_batch).sum()\n",
    "    total += len(y_batch)\n",
    "\n",
    "    batches += 1\n",
    "    if batches % 100 == 0:\n",
    "      print(\"Batch Loss:\", total_loss, \"Accuracy:\", correct.float() / total)\n",
    "  \n",
    "  losses.append(total_loss)\n",
    "  accuracies.append(correct.float() / total)\n",
    "  print(\"Train Loss:\", total_loss, \"Accuracy:\", correct.float() / total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "losses, accuracies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()\n",
    "\n",
    "test_correct = 0\n",
    "test_total = 0\n",
    "\n",
    "for input_ids_batch, attention_masks_batch, y_batch in tqdm(test_loader):\n",
    "  y_batch = y_batch.to(device)\n",
    "  y_pred = model(input_ids_batch.to(device), attention_mask=attention_masks_batch.to(device))[0]\n",
    "  _, predicted = torch.max(y_pred, 1)\n",
    "  test_correct += (predicted == y_batch).sum()\n",
    "  test_total += len(y_batch)\n",
    "\n",
    "print(\"Accuracy:\", test_correct.float() / test_total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델 저장하기\n",
    "torch.save(model.state_dict(), \"model.pt\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ETRI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
